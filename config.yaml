# data_config
dataset_mixer:
  AI-MO/NuminaMath-CoT: 0.001
dataset_splits:
- train
- test
chat_template: "{% for message in messages %}{% if (message['role'] == 'system')%}{{ '' }}{% elif (message['role'] == 'user')%}{{ '### Problem: ' + message['content'] + '\n' }}{% elif (message['role'] == 'assistant')%}{{ '### Solution: ' + message['content'] + '\n' }}{% endif %}{% if loop.last and message['role'] == 'user' and add_generation_prompt %}{{ '### Solution: ' }}{% endif %}{% endfor %}"

# model_config
model_name_or_path: deepseek-ai/deepseek-math-7b-base
torch_dtype: bfloat16
model_revision: main
trust_remote_code: true
attn_implementation: sdpa
use_peft: true
load_in_8bit: true


# sft_config
output_dir: output
packing: true
gradient_checkpointing: false
do_train: true
do_eval: true
max_seq_length: 400
report_to: none
per_device_train_batch_size: 1
per_device_eval_batch_size: 2
logging_steps: 10
eval_strategy: steps
num_train_epochs: 1
eval_steps: 50






